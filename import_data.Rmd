```{r}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(readr)
library(redav)
```

```{r}
raw_df = read_tsv('18k_Projects.csv')
raw_df %>% head()
```

```{r}
# don't need:
# c(-Url, -`Start Timestamp (UTC)`, -`End Timestamp (UTC)`, -`Creator Bio`, -`Creator Website`)
# keep creator info for missing value analysis
raw_df = raw_df %>% select(c(-Url, -`Start Timestamp (UTC)`, -`End Timestamp (UTC)`))
raw_df %>% names()
```

Try1: for duplicate ID, keep those with fewer NAs

```{r}
# delete duplicate rows (5)
clean_df = raw_df %>% distinct()
nrow(raw_df) - nrow(clean_df)
# duplicate ID: 64
nrow(clean_df) - nrow(clean_df %>% distinct(Id, .keep_all=TRUE))

# get NA number for each row
clean_df = clean_df %>% 
  mutate(na_num = rowSums(is.na(.)))
clean_df %>% select(na_num) %>% table()

# for each ID, select the one with fewer NAs
clean_df = clean_df %>% 
  group_by(Id) %>% 
  slice_min(na_num, n=1)
nrow(raw_df) - nrow(clean_df) 
nrow((raw_df)) - nrow(clean_df %>% distinct(Id))
# still 10 is not eliminate because they have the same missing value number
# duplicate_rows <- clean_df[duplicated(clean_df$Id), ] %>% pull(Id)
# clean_df %>% filter(Id %in% duplicate_rows)
clean_df = clean_df %>% distinct(Id, .keep_all=TRUE) %>% as_tibble()
nrow(raw_df) - nrow(clean_df) 


```

Convert data type

```{r}
glimpse(clean_df)
# already converted

```

Store clean data

```{r}
write_csv(clean_df, "18k_Projects_clean.csv")
```

Number of NAs in each columns

```{r}
is.na(clean_df) %>% sum()
col_na = colSums(is.na(clean_df)) %>%
  sort(decreasing = TRUE)
col_na = col_na[col_na > 0]
col_na
```

Spatial information loss is the most frequent. Also the Facebook information, the Creator's number of projects backed. Same for `#Videos` and \`#Words (Risks and Challenges)\`.

Heat maps:

```{r, fig.width=10}
clean_df_miss = clean_df %>% 
  select (col_na %>% names())
names(clean_df_miss) = clean_df_miss %>% names() %>% substr(1,8)

clean_df_miss %>% names()

clean_df_miss %>% 
  plot_missing(percent = TRUE)
```

Around 30% complete cases.

/Missing Patterns:

```{r}
raw_df %>% filter(is.na(`Creator - # Projects Backed`))
raw_df %>% filter(!is.na(`Facebook Friends`))
```

Guessing:

1.  creator project backed & date & project created

2.  note: has video means on the front page. \# video means inside the explanation text.

3.  facebook connected & facebook Friends: If no Facebook connected for the creator, then no information about their Facebook friends.

    ```{r}
    raw_df %>% filter(`Facebook Connected` == 'Yes' & is.na(`Facebook Friends`))
    raw_df %>% filter(`Facebook Connected` == 'No' & (!is.na(`Facebook Friends`)))
    # all return 0 lines
    ```

4.  #word/#video/creator website: 2014.1\~2014.3, maybe manually problem.

5.  issue: long/altti similar to location: redundancy

```{r}
missing_bool <- raw_df %>% 
    rownames_to_column("Id") %>% 
    gather(key, value, -id) %>% 
    mutate(missing = ifelse(is.na(value), "yes", "no"))
missing_bool
```

```{r}
nrow(raw_df)
```

```{r}
nrow(raw_df) - length(raw_df$Id %>% unique())
```

```{r}
nrow(raw_df) - raw_df %>% unique() %>% nrow()
```

```{r}
nrow(raw_df) - raw_df$Name %>% unique() %>% length()
```

```{r}
raw_df = raw_df %>% distinct()
dup_id = raw_df$Id[duplicated(raw_df$Id)]
dup_id %>% length()
raw_df %>% filter(Id %in% dup_id) %>% arrange(Id)
```
